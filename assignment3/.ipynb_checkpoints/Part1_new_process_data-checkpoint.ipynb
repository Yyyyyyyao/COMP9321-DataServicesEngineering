{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "after-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import math\n",
    "import datetime\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brief-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_training = pd.read_csv(\"training.csv\")\n",
    "input_validation = pd.read_csv(\"validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "welsh-minimum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2100 entries, 0 to 2099\n",
      "Data columns (total 19 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   movie_id              2100 non-null   int64  \n",
      " 1   cast                  2100 non-null   object \n",
      " 2   crew                  2100 non-null   object \n",
      " 3   budget                2100 non-null   int64  \n",
      " 4   genres                2100 non-null   object \n",
      " 5   homepage              955 non-null    object \n",
      " 6   keywords              2100 non-null   object \n",
      " 7   original_language     2100 non-null   object \n",
      " 8   original_title        2100 non-null   object \n",
      " 9   overview              2100 non-null   object \n",
      " 10  production_companies  2100 non-null   object \n",
      " 11  production_countries  2100 non-null   object \n",
      " 12  release_date          2100 non-null   object \n",
      " 13  revenue               2100 non-null   int64  \n",
      " 14  runtime               2100 non-null   float64\n",
      " 15  spoken_languages      2100 non-null   object \n",
      " 16  status                2100 non-null   object \n",
      " 17  tagline               2001 non-null   object \n",
      " 18  rating                2100 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(14)\n",
      "memory usage: 311.8+ KB\n"
     ]
    }
   ],
   "source": [
    "input_training.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "resistant-debut",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"cast_id\": 242, \"character\": \"Jake Sully\", \"...</td>\n",
       "      <td>[{\"credit_id\": \"52fe48009251416c750aca23\", \"de...</td>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>[{\"cast_id\": 4, \"character\": \"Captain Jack Spa...</td>\n",
       "      <td>[{\"credit_id\": \"52fe4232c3a36847f800b579\", \"de...</td>\n",
       "      <td>300000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"cast_id\": 1, \"character\": \"James Bond\", \"cr...</td>\n",
       "      <td>[{\"credit_id\": \"54805967c3a36829b5002c41\", \"de...</td>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49026</td>\n",
       "      <td>[{\"cast_id\": 2, \"character\": \"Bruce Wayne / Ba...</td>\n",
       "      <td>[{\"credit_id\": \"52fe4781c3a36847f81398c3\", \"de...</td>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>http://www.thedarkknightrises.com/</td>\n",
       "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "      <td>[{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>1084939099</td>\n",
       "      <td>165.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Legend Ends</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49529</td>\n",
       "      <td>[{\"cast_id\": 5, \"character\": \"John Carter\", \"c...</td>\n",
       "      <td>[{\"credit_id\": \"52fe479ac3a36847f813eaa3\", \"de...</td>\n",
       "      <td>260000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://movies.disney.com/john-carter</td>\n",
       "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-03-07</td>\n",
       "      <td>284139100</td>\n",
       "      <td>132.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Lost in our world, found in another.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                               cast  \\\n",
       "0     19995  [{\"cast_id\": 242, \"character\": \"Jake Sully\", \"...   \n",
       "1       285  [{\"cast_id\": 4, \"character\": \"Captain Jack Spa...   \n",
       "2    206647  [{\"cast_id\": 1, \"character\": \"James Bond\", \"cr...   \n",
       "3     49026  [{\"cast_id\": 2, \"character\": \"Bruce Wayne / Ba...   \n",
       "4     49529  [{\"cast_id\": 5, \"character\": \"John Carter\", \"c...   \n",
       "\n",
       "                                                crew     budget  \\\n",
       "0  [{\"credit_id\": \"52fe48009251416c750aca23\", \"de...  237000000   \n",
       "1  [{\"credit_id\": \"52fe4232c3a36847f800b579\", \"de...  300000000   \n",
       "2  [{\"credit_id\": \"54805967c3a36829b5002c41\", \"de...  245000000   \n",
       "3  [{\"credit_id\": \"52fe4781c3a36847f81398c3\", \"de...  250000000   \n",
       "4  [{\"credit_id\": \"52fe479ac3a36847f813eaa3\", \"de...  260000000   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "2  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "3  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "4  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "\n",
       "                                       homepage  \\\n",
       "0                   http://www.avatarmovie.com/   \n",
       "1  http://disney.go.com/disneypictures/pirates/   \n",
       "2   http://www.sonypictures.com/movies/spectre/   \n",
       "3            http://www.thedarkknightrises.com/   \n",
       "4          http://movies.disney.com/john-carter   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
       "1  [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...                en   \n",
       "2  [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...                en   \n",
       "3  [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...                en   \n",
       "4  [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...                en   \n",
       "\n",
       "                             original_title  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "3                     The Dark Knight Rises   \n",
       "4                               John Carter   \n",
       "\n",
       "                                            overview  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...   \n",
       "1  Captain Barbossa, long believed to be dead, ha...   \n",
       "2  A cryptic message from Bond’s past sends him o...   \n",
       "3  Following the death of District Attorney Harve...   \n",
       "4  John Carter is a war-weary, former military ca...   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
       "1  [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
       "2  [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
       "3  [{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...   \n",
       "4        [{\"name\": \"Walt Disney Pictures\", \"id\": 2}]   \n",
       "\n",
       "                                production_countries release_date     revenue  \\\n",
       "0  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-12-10  2787965087   \n",
       "1  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2007-05-19   961000000   \n",
       "2  [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2015-10-26   880674609   \n",
       "3  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-07-16  1084939099   \n",
       "4  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-03-07   284139100   \n",
       "\n",
       "   runtime                                   spoken_languages    status  \\\n",
       "0    162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...  Released   \n",
       "1    169.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "2    148.0  [{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...  Released   \n",
       "3    165.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "4    132.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "\n",
       "                                          tagline  rating  \n",
       "0                     Enter the World of Pandora.       3  \n",
       "1  At the end of the world, the adventure begins.       3  \n",
       "2                           A Plan No One Escapes       3  \n",
       "3                                 The Legend Ends       3  \n",
       "4            Lost in our world, found in another.       3  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "colonial-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_names(x):\n",
    "    json_data = json.loads(x)\n",
    "    list_genres = []\n",
    "    for token in json_data:\n",
    "        list_genres.append(token['name'])\n",
    "    return list_genres\n",
    "\n",
    "def format_training_data(df_training, df_validation):\n",
    "    training_dataset = pd.DataFrame(columns=['movie_id'])\n",
    "    validation_dataset = pd.DataFrame(columns=['movie_id'])\n",
    "    # movie_id:\n",
    "    training_dataset['movie_id'] = df_training['movie_id']\n",
    "    validation_dataset['movie_id'] = df_validation['movie_id']\n",
    "    \n",
    "    # revenue:\n",
    "    training_dataset['revenue'] = df_training['revenue']\n",
    "    validation_dataset['revenue'] = df_validation['revenue']\n",
    "    \n",
    "\n",
    "    # budget\n",
    "    training_dataset['budget'] = df_training['budget']\n",
    "    validation_dataset['budget'] = df_validation['budget']\n",
    "    \n",
    "    # rating\n",
    "    \n",
    "    # homepage:\n",
    "    training_dataset['has_homepage'] = 0\n",
    "    training_dataset.loc[df_training['homepage'].isnull() == False, 'has_homepage'] = 1 #1 here means it has home page\n",
    "    \n",
    "    validation_dataset['has_homepage'] = 0\n",
    "    validation_dataset.loc[df_validation['homepage'].isnull() == False, 'has_homepage'] = 1 #1 here means it has home page\n",
    "    \n",
    "    # original_language:\n",
    "    unique_languages = list(df_training[\"original_language\"].apply(pd.Series).stack().unique())\n",
    "    for language in unique_languages :\n",
    "        training_dataset[language] = df_training['original_language'].apply(lambda x: 1 if x == language else 0)\n",
    "    for language in unique_languages :\n",
    "        validation_dataset[language] = df_validation['original_language'].apply(lambda x: 1 if x == language else 0)\n",
    "    \n",
    "    # Genres: # may improve by looking at how correlated to revenue\n",
    "#     unique_genres = list(training_dataset[\"genres\"].apply(pd.Series).stack().unique())\n",
    "\n",
    "    # get top 10 mean-revenue genres\n",
    "#     temp = df_training[['movie_id','revenue','genres']].copy()\n",
    "#     temp['genres'] = input_training['genres'].apply(lambda x: get_json_names(x))\n",
    "#     unique_genres = list(temp[\"genres\"].apply(pd.Series).stack().unique())\n",
    "\n",
    "#     dic={}\n",
    "#     for a in unique_genres:\n",
    "#         mask = temp['genres'].apply(lambda x: a in x)\n",
    "#         dic[a] = temp[mask]['revenue'].mean()\n",
    "\n",
    "#     t = pd.DataFrame.from_dict(dic, orient='index', columns=['mean_revenue']).reset_index().rename(columns={'index':'genre'})\n",
    "#     genres_list = list(t.sort_values(by=[\"mean_revenue\"],ascending=False)[\"genre\"])[:10]\n",
    "    \n",
    "    \n",
    "    # get  10 most appearing\n",
    "    temp = input_training[['movie_id','revenue','genres']].copy()\n",
    "    temp['genres'] = temp['genres'].apply(lambda x: get_json_names(x))\n",
    "    genres_list = list(temp['genres'].apply(pd.Series).stack().value_counts().index)[:10]\n",
    "    \n",
    "    \n",
    "#     genres_list=['Drama','Action','Comedy','Thriller','Adventure','Crime','Romance','Science Fiction','Family','Fantasy']\n",
    "    training_dataset['genres'] = df_training['genres'].apply(lambda x: get_json_names(x))\n",
    "    for genres in genres_list :\n",
    "        training_dataset['genre_'+genres]=training_dataset['genres'].apply(lambda x: 1 if genres in x else 0)\n",
    "    training_dataset = training_dataset.drop(['genres'], axis=1)\n",
    "\n",
    "    validation_dataset['genres'] = df_validation['genres'].apply(lambda x: get_json_names(x))\n",
    "    for genres in genres_list :\n",
    "        validation_dataset['genre_'+genres]=validation_dataset['genres'].apply(lambda x: 1 if genres in x else 0)\n",
    "    validation_dataset = validation_dataset.drop(['genres'], axis=1)\n",
    "\n",
    "    # Production company\n",
    "#     production_company_list = ['Warner Bros.', 'Universal Pictures', 'Paramount Pictures', 'Twentieth Century Fox Film Corporation', 'Columbia Pictures']\n",
    "    # top 10 companies who produce most movies\n",
    "    temp = input_training[['movie_id','revenue','production_companies']].copy()\n",
    "    temp['production_companies'] = input_training['production_companies'].apply(lambda x: get_json_names(x))\n",
    "    production_company_list = list(temp['production_companies'].apply(pd.Series).stack().value_counts().index)[:10]\n",
    "    \n",
    "    training_dataset['production_companies'] = df_training['production_companies'].apply(lambda x: get_json_names(x))\n",
    "    for company in production_company_list :\n",
    "        training_dataset['company_'+company]=training_dataset['production_companies'].apply(lambda x: 1 if company in x else 0)\n",
    "    training_dataset = training_dataset.drop(['production_companies'], axis=1)\n",
    "    \n",
    "    validation_dataset['production_companies'] = df_validation['production_companies'].apply(lambda x: get_json_names(x))\n",
    "    for company in production_company_list :\n",
    "        validation_dataset['company_'+company]=validation_dataset['production_companies'].apply(lambda x: 1 if company in x else 0)\n",
    "    validation_dataset = validation_dataset.drop(['production_companies'], axis=1)\n",
    "    \n",
    "    \n",
    "    # crew \n",
    "    temp = df_training[['movie_id','revenue','crew']].copy()\n",
    "    temp['crew'] = temp['crew'].apply(lambda x: get_json_names(x))\n",
    "    crew_list = list(temp['crew'].apply(pd.Series).stack().value_counts().index)[:10]\n",
    "    \n",
    "    training_dataset['crew'] = df_training['crew'].apply(lambda x: get_json_names(x))\n",
    "    for crew in crew_list :\n",
    "        training_dataset['crew_'+crew]=training_dataset['crew'].apply(lambda x: 1 if crew in x else 0)\n",
    "    training_dataset = training_dataset.drop(['crew'], axis=1)\n",
    "    \n",
    "    validation_dataset['crew'] = df_validation['crew'].apply(lambda x: get_json_names(x))\n",
    "    for crew in crew_list :\n",
    "        validation_dataset['crew_'+crew]=validation_dataset['crew'].apply(lambda x: 1 if crew in x else 0)\n",
    "    validation_dataset = validation_dataset.drop(['crew'], axis=1)\n",
    "    \n",
    "    # runtime\n",
    "#     training_dataset['runtime'] = df_training['runtime']\n",
    "#     validation_dataset['runtime'] = df_validation['runtime']\n",
    "    training_dataset['runtime_cat_min_60'] = df_training['runtime'].apply(lambda x: 1 if (x <=60) else 0)\n",
    "    training_dataset['runtime_cat_61_80'] = df_training['runtime'].apply(lambda x: 1 if (x >60)&(x<=80) else 0)\n",
    "    training_dataset['runtime_cat_81_100'] = df_training['runtime'].apply(lambda x: 1 if (x >80)&(x<=100) else 0)\n",
    "    training_dataset['runtime_cat_101_120'] = df_training['runtime'].apply(lambda x: 1 if (x >100)&(x<=120) else 0)\n",
    "    training_dataset['runtime_cat_121_140'] = df_training['runtime'].apply(lambda x: 1 if (x >120)&(x<=140) else 0)\n",
    "    training_dataset['runtime_cat_141_170'] = df_training['runtime'].apply(lambda x: 1 if (x >140)&(x<=170) else 0)\n",
    "    training_dataset['runtime_cat_171_max'] = df_training['runtime'].apply(lambda x: 1 if (x >=170) else 0)\n",
    "    \n",
    "    validation_dataset['runtime_cat_min_60'] = df_validation['runtime'].apply(lambda x: 1 if (x <=60) else 0)\n",
    "    validation_dataset['runtime_cat_61_80'] = df_validation['runtime'].apply(lambda x: 1 if (x >60)&(x<=80) else 0)\n",
    "    validation_dataset['runtime_cat_81_100'] = df_validation['runtime'].apply(lambda x: 1 if (x >80)&(x<=100) else 0)\n",
    "    validation_dataset['runtime_cat_101_120'] = df_validation['runtime'].apply(lambda x: 1 if (x >100)&(x<=120) else 0)\n",
    "    validation_dataset['runtime_cat_121_140'] = df_validation['runtime'].apply(lambda x: 1 if (x >120)&(x<=140) else 0)\n",
    "    validation_dataset['runtime_cat_141_170'] = df_validation['runtime'].apply(lambda x: 1 if (x >140)&(x<=170) else 0)\n",
    "    validation_dataset['runtime_cat_171_max'] = df_validation['runtime'].apply(lambda x: 1 if (x >=170) else 0)\n",
    "    \n",
    "    # release date\n",
    "    training_dataset['release_date'] = pd.to_datetime(df_training['release_date'])\n",
    "    validation_dataset['release_date'] = pd.to_datetime(df_validation['release_date'])\n",
    "    \n",
    "    date_parts = [\"year\", \"weekday\", \"month\"]\n",
    "    for part in date_parts:\n",
    "        part_col = 'release_date' + \"_\" + part #add prefix as  \"release_date\" before the columne\n",
    "        training_dataset[part_col] = getattr(training_dataset['release_date'].dt, part).astype(int)\n",
    "        validation_dataset[part_col] = getattr(validation_dataset['release_date'].dt, part).astype(int)\n",
    "    training_dataset = training_dataset.drop(['release_date'], axis=1)\n",
    "    validation_dataset = validation_dataset.drop(['release_date'], axis=1)\n",
    "    \n",
    "    # keyword\n",
    "    # get 10 most appearing\n",
    "    temp = input_training[['movie_id','revenue','keywords']].copy()\n",
    "    temp['keywords'] = temp['keywords'].apply(lambda x: get_json_names(x))\n",
    "    keywords_list = list(temp['keywords'].apply(pd.Series).stack().value_counts().index)[:10]\n",
    "    \n",
    "    training_dataset['keywords'] = df_training['keywords'].apply(lambda x: get_json_names(x))\n",
    "    for keyword in keywords_list :\n",
    "        training_dataset['keyword_'+keyword]=training_dataset['keywords'].apply(lambda x: 1 if keyword in x else 0)\n",
    "    training_dataset = training_dataset.drop(['keywords'], axis=1)\n",
    "\n",
    "    validation_dataset['keywords'] = df_validation['keywords'].apply(lambda x: get_json_names(x))\n",
    "    for keyword in keywords_list :\n",
    "        validation_dataset['keyword_'+keyword]=validation_dataset['keywords'].apply(lambda x: 1 if keyword in x else 0)\n",
    "    validation_dataset = validation_dataset.drop(['keywords'], axis=1)\n",
    "    \n",
    "    # production_countries\n",
    "    # top 10 countries who produce most movies\n",
    "#     temp = input_training[['movie_id','revenue','production_countries']].copy()\n",
    "#     temp['production_countries'] = input_training['production_countries'].apply(lambda x: get_json_names(x))\n",
    "#     production_countries_list = list(temp['production_countries'].apply(pd.Series).stack().value_counts().index)[:10]\n",
    "    \n",
    "#     training_dataset['production_countries'] = df_training['production_countries'].apply(lambda x: get_json_names(x))\n",
    "#     for country in production_countries_list :\n",
    "#         training_dataset['country_'+country]=training_dataset['production_countries'].apply(lambda x: 1 if country in x else 0)\n",
    "#     training_dataset = training_dataset.drop(['production_countries'], axis=1)\n",
    "    \n",
    "#     validation_dataset['production_countries'] = df_validation['production_countries'].apply(lambda x: get_json_names(x))\n",
    "#     for country in production_countries_list :\n",
    "#         validation_dataset['country_'+country]=validation_dataset['production_countries'].apply(lambda x: 1 if country in x else 0)\n",
    "#     validation_dataset = validation_dataset.drop(['production_countries'], axis=1)\n",
    "    \n",
    "    \n",
    "    # cast\n",
    "#     temp = df_training[['movie_id','revenue','cast']].copy()\n",
    "#     temp['cast'] = temp['cast'].apply(lambda x: get_json_names(x))\n",
    "#     cast_list = list(temp['cast'].apply(pd.Series).stack().value_counts().index)[:10]\n",
    "    \n",
    "#     training_dataset['cast'] = df_training['cast'].apply(lambda x: get_json_names(x))\n",
    "#     for cast in cast_list :\n",
    "#         training_dataset['cast_'+cast]=training_dataset['cast'].apply(lambda x: 1 if cast in x else 0)\n",
    "#     training_dataset = training_dataset.drop(['cast'], axis=1)\n",
    "    \n",
    "#     validation_dataset['cast'] = df_validation['cast'].apply(lambda x: get_json_names(x))\n",
    "#     for cast in cast_list :\n",
    "#         validation_dataset['cast_'+cast]=validation_dataset['cast'].apply(lambda x: 1 if cast in x else 0)\n",
    "#     validation_dataset = validation_dataset.drop(['cast'], axis=1)\n",
    "    \n",
    "    \n",
    "    # spoken_languages\n",
    "#     temp = df_training[['movie_id','revenue','spoken_languages']].copy()\n",
    "#     temp['spoken_languages'] = temp['spoken_languages'].apply(lambda x: get_json_names(x))\n",
    "#     spoken_languages_list = list(temp['spoken_languages'].apply(pd.Series).stack().value_counts().index)[:10]\n",
    "    \n",
    "#     training_dataset['spoken_languages'] = df_training['spoken_languages'].apply(lambda x: get_json_names(x))\n",
    "#     for lang in spoken_languages_list :\n",
    "#         training_dataset['spoken_languages_'+lang]=training_dataset['spoken_languages'].apply(lambda x: 1 if lang in x else 0)\n",
    "#     training_dataset = training_dataset.drop(['spoken_languages'], axis=1)\n",
    "    \n",
    "#     validation_dataset['spoken_languages'] = df_validation['spoken_languages'].apply(lambda x: get_json_names(x))\n",
    "#     for lang in spoken_languages_list :\n",
    "#         validation_dataset['spoken_languages_'+lang]=validation_dataset['spoken_languages'].apply(lambda x: 1 if lang in x else 0)\n",
    "#     validation_dataset = validation_dataset.drop(['spoken_languages'], axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return training_dataset, validation_dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "endless-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset, validation_dataset = format_training_data(input_training, input_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "champion-jamaica",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2100 entries, 0 to 2099\n",
      "Data columns (total 76 columns):\n",
      " #   Column                                          Non-Null Count  Dtype\n",
      "---  ------                                          --------------  -----\n",
      " 0   movie_id                                        2100 non-null   int64\n",
      " 1   revenue                                         2100 non-null   int64\n",
      " 2   budget                                          2100 non-null   int64\n",
      " 3   has_homepage                                    2100 non-null   int64\n",
      " 4   en                                              2100 non-null   int64\n",
      " 5   ja                                              2100 non-null   int64\n",
      " 6   fr                                              2100 non-null   int64\n",
      " 7   zh                                              2100 non-null   int64\n",
      " 8   ko                                              2100 non-null   int64\n",
      " 9   te                                              2100 non-null   int64\n",
      " 10  ru                                              2100 non-null   int64\n",
      " 11  de                                              2100 non-null   int64\n",
      " 12  cn                                              2100 non-null   int64\n",
      " 13  es                                              2100 non-null   int64\n",
      " 14  it                                              2100 non-null   int64\n",
      " 15  nl                                              2100 non-null   int64\n",
      " 16  genre_Drama                                     2100 non-null   int64\n",
      " 17  genre_Action                                    2100 non-null   int64\n",
      " 18  genre_Comedy                                    2100 non-null   int64\n",
      " 19  genre_Thriller                                  2100 non-null   int64\n",
      " 20  genre_Adventure                                 2100 non-null   int64\n",
      " 21  genre_Crime                                     2100 non-null   int64\n",
      " 22  genre_Romance                                   2100 non-null   int64\n",
      " 23  genre_Science Fiction                           2100 non-null   int64\n",
      " 24  genre_Family                                    2100 non-null   int64\n",
      " 25  genre_Fantasy                                   2100 non-null   int64\n",
      " 26  company_Warner Bros.                            2100 non-null   int64\n",
      " 27  company_Universal Pictures                      2100 non-null   int64\n",
      " 28  company_Paramount Pictures                      2100 non-null   int64\n",
      " 29  company_Twentieth Century Fox Film Corporation  2100 non-null   int64\n",
      " 30  company_Columbia Pictures                       2100 non-null   int64\n",
      " 31  company_New Line Cinema                         2100 non-null   int64\n",
      " 32  company_Relativity Media                        2100 non-null   int64\n",
      " 33  company_Walt Disney Pictures                    2100 non-null   int64\n",
      " 34  company_Touchstone Pictures                     2100 non-null   int64\n",
      " 35  company_Village Roadshow Pictures               2100 non-null   int64\n",
      " 36  crew_Robert Rodriguez                           2100 non-null   int64\n",
      " 37  crew_Steven Spielberg                           2100 non-null   int64\n",
      " 38  crew_Hans Zimmer                                2100 non-null   int64\n",
      " 39  crew_James Newton Howard                        2100 non-null   int64\n",
      " 40  crew_Francine Maisler                           2100 non-null   int64\n",
      " 41  crew_Deborah Aquila                             2100 non-null   int64\n",
      " 42  crew_Mary Vernieu                               2100 non-null   int64\n",
      " 43  crew_Kevin Kaska                                2100 non-null   int64\n",
      " 44  crew_Dan O'Connell                              2100 non-null   int64\n",
      " 45  crew_Avy Kaufman                                2100 non-null   int64\n",
      " 46  runtime_cat_min_60                              2100 non-null   int64\n",
      " 47  runtime_cat_61_80                               2100 non-null   int64\n",
      " 48  runtime_cat_81_100                              2100 non-null   int64\n",
      " 49  runtime_cat_101_120                             2100 non-null   int64\n",
      " 50  runtime_cat_121_140                             2100 non-null   int64\n",
      " 51  runtime_cat_141_170                             2100 non-null   int64\n",
      " 52  runtime_cat_171_max                             2100 non-null   int64\n",
      " 53  release_date_year                               2100 non-null   int64\n",
      " 54  release_date_weekday                            2100 non-null   int64\n",
      " 55  release_date_month                              2100 non-null   int64\n",
      " 56  keyword_duringcreditsstinger                    2100 non-null   int64\n",
      " 57  keyword_based on novel                          2100 non-null   int64\n",
      " 58  keyword_aftercreditsstinger                     2100 non-null   int64\n",
      " 59  keyword_dystopia                                2100 non-null   int64\n",
      " 60  keyword_3d                                      2100 non-null   int64\n",
      " 61  keyword_violence                                2100 non-null   int64\n",
      " 62  keyword_woman director                          2100 non-null   int64\n",
      " 63  keyword_murder                                  2100 non-null   int64\n",
      " 64  keyword_sequel                                  2100 non-null   int64\n",
      " 65  keyword_revenge                                 2100 non-null   int64\n",
      " 66  spoken_languages_English                        2100 non-null   int64\n",
      " 67  spoken_languages_Français                       2100 non-null   int64\n",
      " 68  spoken_languages_Español                        2100 non-null   int64\n",
      " 69  spoken_languages_Deutsch                        2100 non-null   int64\n",
      " 70  spoken_languages_Pусский                        2100 non-null   int64\n",
      " 71  spoken_languages_Italiano                       2100 non-null   int64\n",
      " 72  spoken_languages_普通话                            2100 non-null   int64\n",
      " 73  spoken_languages_日本語                            2100 non-null   int64\n",
      " 74  spoken_languages_العربية                        2100 non-null   int64\n",
      " 75  spoken_languages_Português                      2100 non-null   int64\n",
      "dtypes: int64(76)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "training_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "religious-nowhere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>revenue</th>\n",
       "      <th>budget</th>\n",
       "      <th>has_homepage</th>\n",
       "      <th>en</th>\n",
       "      <th>ja</th>\n",
       "      <th>fr</th>\n",
       "      <th>zh</th>\n",
       "      <th>ko</th>\n",
       "      <th>te</th>\n",
       "      <th>...</th>\n",
       "      <th>spoken_languages_English</th>\n",
       "      <th>spoken_languages_Français</th>\n",
       "      <th>spoken_languages_Español</th>\n",
       "      <th>spoken_languages_Deutsch</th>\n",
       "      <th>spoken_languages_Pусский</th>\n",
       "      <th>spoken_languages_Italiano</th>\n",
       "      <th>spoken_languages_普通话</th>\n",
       "      <th>spoken_languages_日本語</th>\n",
       "      <th>spoken_languages_العربية</th>\n",
       "      <th>spoken_languages_Português</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19994</td>\n",
       "      <td>31556061</td>\n",
       "      <td>16000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25166</td>\n",
       "      <td>15427192</td>\n",
       "      <td>16000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12120</td>\n",
       "      <td>13854000</td>\n",
       "      <td>20000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9800</td>\n",
       "      <td>206678440</td>\n",
       "      <td>26000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1090</td>\n",
       "      <td>18564088</td>\n",
       "      <td>16000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>7942</td>\n",
       "      <td>33000000</td>\n",
       "      <td>10000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>73247</td>\n",
       "      <td>2154696</td>\n",
       "      <td>10000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>253331</td>\n",
       "      <td>21571189</td>\n",
       "      <td>9000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>9952</td>\n",
       "      <td>7177143</td>\n",
       "      <td>10000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>256924</td>\n",
       "      <td>10835752</td>\n",
       "      <td>10000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     movie_id    revenue    budget  has_homepage  en  ja  fr  zh  ko  te  ...  \\\n",
       "0       19994   31556061  16000000             0   1   0   0   0   0   0  ...   \n",
       "1       25166   15427192  16000000             0   1   0   0   0   0   0  ...   \n",
       "2       12120   13854000  20000000             0   1   0   0   0   0   0  ...   \n",
       "3        9800  206678440  26000000             0   1   0   0   0   0   0  ...   \n",
       "4        1090   18564088  16000000             0   1   0   0   0   0   0  ...   \n",
       "..        ...        ...       ...           ...  ..  ..  ..  ..  ..  ..  ...   \n",
       "395      7942   33000000  10000000             1   1   0   0   0   0   0  ...   \n",
       "396     73247    2154696  10000000             0   1   0   0   0   0   0  ...   \n",
       "397    253331   21571189   9000000             0   1   0   0   0   0   0  ...   \n",
       "398      9952    7177143  10000000             0   1   0   0   0   0   0  ...   \n",
       "399    256924   10835752  10000000             0   1   0   0   0   0   0  ...   \n",
       "\n",
       "     spoken_languages_English  spoken_languages_Français  \\\n",
       "0                           1                          0   \n",
       "1                           1                          0   \n",
       "2                           1                          0   \n",
       "3                           1                          0   \n",
       "4                           1                          0   \n",
       "..                        ...                        ...   \n",
       "395                         1                          0   \n",
       "396                         1                          0   \n",
       "397                         1                          0   \n",
       "398                         1                          0   \n",
       "399                         1                          0   \n",
       "\n",
       "     spoken_languages_Español  spoken_languages_Deutsch  \\\n",
       "0                           1                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "..                        ...                       ...   \n",
       "395                         0                         0   \n",
       "396                         0                         0   \n",
       "397                         0                         0   \n",
       "398                         0                         0   \n",
       "399                         0                         0   \n",
       "\n",
       "     spoken_languages_Pусский  spoken_languages_Italiano  \\\n",
       "0                           0                          0   \n",
       "1                           0                          0   \n",
       "2                           0                          0   \n",
       "3                           0                          0   \n",
       "4                           0                          0   \n",
       "..                        ...                        ...   \n",
       "395                         0                          0   \n",
       "396                         0                          0   \n",
       "397                         0                          0   \n",
       "398                         0                          0   \n",
       "399                         0                          1   \n",
       "\n",
       "     spoken_languages_普通话  spoken_languages_日本語  spoken_languages_العربية  \\\n",
       "0                       0                     0                         0   \n",
       "1                       0                     0                         0   \n",
       "2                       0                     0                         0   \n",
       "3                       0                     0                         0   \n",
       "4                       0                     0                         0   \n",
       "..                    ...                   ...                       ...   \n",
       "395                     0                     0                         0   \n",
       "396                     0                     0                         0   \n",
       "397                     0                     0                         0   \n",
       "398                     0                     0                         0   \n",
       "399                     0                     0                         0   \n",
       "\n",
       "     spoken_languages_Português  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             0  \n",
       "..                          ...  \n",
       "395                           0  \n",
       "396                           0  \n",
       "397                           0  \n",
       "398                           0  \n",
       "399                           0  \n",
       "\n",
       "[400 rows x 76 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation_dataset[validation_dataset['crew_Robert Rodriguez']==1]\n",
    "validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "coastal-sucking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared is: -4.017340765495016\n"
     ]
    }
   ],
   "source": [
    "train_X = training_dataset.drop(['revenue'], axis=1)\n",
    "\n",
    "# log\n",
    "train_X['budget'] = train_X['budget'].apply(lambda x: math.log(x))\n",
    "train_y = training_dataset['revenue'].apply(lambda x: math.log(x))\n",
    "\n",
    "# #normal \n",
    "# train_y = training_dataset['revenue']\n",
    "\n",
    "test_X = validation_dataset.drop(['revenue'], axis=1)\n",
    "\n",
    "# log\n",
    "test_X['budget'] = test_X['budget'].apply(lambda x: math.log(x))\n",
    "test_y = validation_dataset['revenue'].apply(lambda x: math.log(x))\n",
    "\n",
    "# #normal\n",
    "# train_y = training_dataset['revenue']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, random_state = 1)\n",
    "#linear regression\n",
    "lm = LinearRegression() #our 6th model\n",
    "lm.fit(train_X, train_y)\n",
    "lm_preds = lm.predict(test_X)\n",
    "a = mean_squared_error(lm_preds, test_y)\n",
    "print (\"R-Squared is:\", r2_score(lm_preds, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "official-democracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_log Pearsons correlation: 0.294\n",
      "log Pearsons correlation: 0.415\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr, _ = pearsonr(np.exp(lm_preds), np.exp(test_y))\n",
    "print('non_log Pearsons correlation: %.3f' % corr)\n",
    "corr, _ = pearsonr(lm_preds, test_y)\n",
    "print('log Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "excess-stroke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_log Pearsons correlation: 0.359\n",
      "log Pearsons correlation: 0.427\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RF_model = RandomForestRegressor(random_state =0, n_estimators=500, max_depth=10)\n",
    "RF_model.fit(train_X, train_y)\n",
    "\n",
    "y_hat = RF_model.predict(test_X)\n",
    "corr, _ = pearsonr(np.exp(y_hat), np.exp(test_y))\n",
    "print('non_log Pearsons correlation: %.3f' % corr)\n",
    "corr, _ = pearsonr(y_hat, test_y)\n",
    "print('log Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "arbitrary-python",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.6467649856727629\n",
      "non_log Pearsons correlation: 0.503\n",
      "log Pearsons correlation: 0.444\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "          'learning_rate': .01, 'loss': 'ls'} \n",
    "clf = ensemble.GradientBoostingRegressor(**params)\n",
    "predictions2 = clf.fit(train_X,train_y)\n",
    "training_score = clf.score(train_X, train_y)\n",
    "print(f\"Training Score: {training_score}\")\n",
    "\n",
    "predictions2 = clf.predict(test_X).reshape(-1,1)\n",
    "MSE = mean_squared_error(test_y, predictions2)\n",
    "# r2 = clf.score(predictions2, test_y)\n",
    "# print(f\"MSE: {MSE}, R2: {r2}\")\n",
    "# corr, _ = pearsonr(np.exp(predictions2), np.exp(test_y))\n",
    "# print('non_log Pearsons correlation: %.3f' % corr)\n",
    "# corr, _ = pearsonr(predictions2, test_y)\n",
    "# print('log Pearsons correlation: %.3f' % corr)\n",
    "i = 0\n",
    "preds=[]\n",
    "while(i < len(predictions2)):\n",
    "    preds.append(predictions2[i][0])\n",
    "    i += 1\n",
    "    \n",
    "corr, _ = pearsonr(np.exp(preds), np.exp(test_y))\n",
    "print('non_log Pearsons correlation: %.3f' % corr)\n",
    "corr, _ = pearsonr(preds, test_y)\n",
    "print('log Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "identical-peripheral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.219704618856619"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "closed-plymouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Warner Bros.                              242\n",
       "Universal Pictures                        218\n",
       "Paramount Pictures                        184\n",
       "Twentieth Century Fox Film Corporation    155\n",
       "Columbia Pictures                         148\n",
       "                                         ... \n",
       "Bluewater Pictures                          1\n",
       "Safady Entertainment                        1\n",
       "Bandito Brothers                            1\n",
       "Soho VFX                                    1\n",
       "Seed Productions                            1\n",
       "Length: 2347, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = input_training[['movie_id','revenue','crew']].copy()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "congressional-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "temp = input_training[['movie_id','revenue','crew']].copy()\n",
    "temp['crew'] = input_training['crew'].apply(lambda x: get_json_names(x))\n",
    "crew_list = list(temp['crew'].apply(pd.Series).stack().value_counts().index)[:10]\n",
    "# temp['crew'] = temp['crew'].apply(lambda x: x[:10])\n",
    "\n",
    "# names = temp['crew'].sum()\n",
    "# ctr = Counter(names)\n",
    "# df_names = pd.DataFrame.from_dict(ctr, orient='index').reset_index().rename(columns={'index':'actor', 0:'count'})       \n",
    "# df_names=df_names.sort_values('count', ascending=False)\n",
    "# df_names = df_names[df_names['count'] > 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "jewish-defensive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Robert Rodriguez       83\n",
       "Steven Spielberg       74\n",
       "Hans Zimmer            63\n",
       "James Newton Howard    55\n",
       "Francine Maisler       55\n",
       "                       ..\n",
       "William Bonn            1\n",
       "Mariano Carranco        1\n",
       "Carlos Barbosa          1\n",
       "Anupam Das              1\n",
       "Giulio Tamassy          1\n",
       "Length: 35208, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['crew'].apply(pd.Series).stack().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "prospective-gallery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Robert Rodriguez',\n",
       " 'Steven Spielberg',\n",
       " 'Hans Zimmer',\n",
       " 'James Newton Howard',\n",
       " 'Francine Maisler',\n",
       " 'Deborah Aquila',\n",
       " 'Mary Vernieu',\n",
       " 'Kevin Kaska',\n",
       " \"Dan O'Connell\",\n",
       " 'Avy Kaufman']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crew_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "turkish-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = input_training[['movie_id','revenue','keywords']].copy()\n",
    "temp['keywords'] = temp['keywords'].apply(lambda x: get_json_names(x))\n",
    "keywords_list = list(temp['keywords'].apply(pd.Series).stack().value_counts().index)[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "inside-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duringcreditsstinger    210\n",
       "based on novel          132\n",
       "aftercreditsstinger     114\n",
       "dystopia                100\n",
       "3d                       87\n",
       "                       ... \n",
       "wealth differences        1\n",
       "stage                     1\n",
       "people change             1\n",
       "baader-meinhof group      1\n",
       "insider                   1\n",
       "Length: 6681, dtype: int64"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['keywords'].apply(pd.Series).stack().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-dictionary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
